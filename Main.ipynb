{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc825eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase Of Update\n",
    "response = requests.get('https://db.ygoprodeck.com/api/v7/cardinfo.php')\n",
    "json_response = response.json()\n",
    "dataset = pd.DataFrame(json_response['data'])\n",
    "\n",
    "dataset.to_csv('Dataset/Yugioh_Database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc1ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import random as random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "plt.style.use('Solarize_Light2')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "#import requests\n",
    "#import itertools\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef56086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "'''Load Dataset'''\n",
    "dataset = pd.read_csv('Dataset/Yugioh_Database.csv')\n",
    "dataset = dataset.drop(['Unnamed: 0' , 'frameType' , 'archetype' , 'ygoprodeck_url' , 'card_sets' , 'card_images' , 'card_prices' , 'banlist_info'],axis=1)\n",
    "dataset = dataset[dataset['type'] != 'XYZ Pendulum Effect Monster']\n",
    "dataset = dataset[dataset['type'] != 'Synchro Pendulum Effect Monster']\n",
    "dataset = dataset[dataset['type'] != 'Fusion Pendulum Effect Monster']\n",
    "dataset = dataset[dataset['type'] != 'Pendulum Effect Monster']\n",
    "dataset = dataset[dataset['type'] != 'Pendulum Normal Monster']\n",
    "\n",
    "dataset = dataset[dataset['type'] != 'Skill Card']\n",
    "dataset = dataset[dataset['type'] != 'Monster Token']\n",
    "# Staple Removal\n",
    "dataset = dataset[[not i for i in dataset['name'].isin(['Ash Blossom & Joyous Spring' , 'Effect Veiler' , 'Ghost Ogre & Snow Rabbit' ,'Ghost Belle & Haunted Mansion',\n",
    "                                                        'Infinite Impermanence' , 'Red Reboot' , 'Called by the Grave' , 'Forbidden Droplet' , 'Crossout Designator',\n",
    "                                                        'Nibiru, the Primal Being', 'Harpie\\\"s Feather Duster' , 'Lightning Storm' , 'Pot of Prosperity' , 'Pot of Desires',\n",
    "                                                        'Pot of Duality' , 'Pot of Extravagance' , 'Triple Tactics Talents' , 'Torrential Tribute' , 'Dark Ruler No More' , \n",
    "                                                        'Red Reboot', 'D.D. Crow' , 'PSY-Framegear Gamma' , 'Maxx \\\"C\\\"' , 'Dimension Shifter' , 'Droll & Lock Bird' , \n",
    "                                                        'Accesscode Talker', 'Apollousa, Bow of the Goddess', 'Borreload Dragon' , 'Borrelsword Dragon', 'Knightmare Unicorn',\n",
    "                                                        'Predaplant Verte Anaconda' , 'Knightmare Phoenix' , 'Knightmare Cerberus' , 'Underworld Goddess of the Closed World',\n",
    "                                                        'Borreload Savage Dragon'])]]\n",
    "\n",
    "dataset.loc[dataset['type']=='Normal Monster', ['desc']] = 'NoInfo'\n",
    "dataset = dataset.fillna('0')\n",
    "dataset['level'] = dataset['level'].astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "'''Create Tokenized sequence database'''\n",
    "\n",
    "\n",
    "df = dataset['desc']         #Tokenizer is only trained on desc and based on that . Otherwise if trained on names it would blow vocab up to absurd amounts\n",
    "Sliced_df = dataset[['level' , 'race' , 'type' , 'attribute' , 'name' , 'desc']]\n",
    "\n",
    "for i in range(1,11,2):\n",
    "    Sliced_df.insert(loc=i, column='A'+str(i), value=-1)        # Adds seperator columns\n",
    "\n",
    "\n",
    "Sliced_df = Sliced_df.reset_index(drop=True)            # Need to reset the indexes so they are consistent\n",
    "df = df.reset_index(drop=True)                              \n",
    "\n",
    "tokenizer = Tokenizer(filters='\\r , \\n , \\\" ') # Speech marks stop names from being recognised by tokenizer\n",
    "tokenizer.fit_on_texts(df)\n",
    "tokenizer.word_index['0'] = 0           #Signifies Empty values\n",
    "tokenizer.word_index['-1'] = -1           #Signifies Seperators\n",
    "\n",
    "sequences = []\n",
    "padded_sequences = []\n",
    "Tokenized_sequence_database = []\n",
    "count = 0\n",
    "for i in Sliced_df.astype('string').to_numpy():\n",
    "    \n",
    "    sequences.append(tokenizer.texts_to_sequences(i))\n",
    "    \n",
    "\n",
    "for i in range(0,11):\n",
    "    padded_sequences.append( pad_sequences(np.array(sequences , dtype='object')[:,i], padding='post') ) \n",
    "\n",
    "Tokenized_sequence_database = np.concatenate(([padded_sequences[i] for i in range(11)]) , axis=1 )\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>A1</th>\n",
       "      <th>race</th>\n",
       "      <th>A3</th>\n",
       "      <th>type</th>\n",
       "      <th>A5</th>\n",
       "      <th>attribute</th>\n",
       "      <th>A7</th>\n",
       "      <th>name</th>\n",
       "      <th>A9</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spell Card</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"A\" Cell Breeding Device</td>\n",
       "      <td>-1</td>\n",
       "      <td>During each of your Standby Phases, put 1 A-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spell Card</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"A\" Cell Incubator</td>\n",
       "      <td>-1</td>\n",
       "      <td>Each time an A-Counter(s) is removed from play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Quick-Play</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spell Card</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"A\" Cell Recombination Device</td>\n",
       "      <td>-1</td>\n",
       "      <td>Target 1 face-up monster on the field; send 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Quick-Play</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spell Card</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"A\" Cell Scatter Burst</td>\n",
       "      <td>-1</td>\n",
       "      <td>Select 1 face-up \"Alien\" monster you control. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Equip</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spell Card</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>\"Infernoble Arms - Almace\"</td>\n",
       "      <td>-1</td>\n",
       "      <td>While this card is equipped to a monster: You ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Beast</td>\n",
       "      <td>-1</td>\n",
       "      <td>Effect Monster</td>\n",
       "      <td>-1</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>-1</td>\n",
       "      <td>ZW - Sleipnir Mail</td>\n",
       "      <td>-1</td>\n",
       "      <td>You can target 1 \"Utopia\" monster you control;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12457</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Beast</td>\n",
       "      <td>-1</td>\n",
       "      <td>Effect Monster</td>\n",
       "      <td>-1</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>-1</td>\n",
       "      <td>ZW - Sylphid Wing</td>\n",
       "      <td>-1</td>\n",
       "      <td>You can only control 1 \"ZW - Sylphid Wing\". Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12458</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>-1</td>\n",
       "      <td>Effect Monster</td>\n",
       "      <td>-1</td>\n",
       "      <td>WIND</td>\n",
       "      <td>-1</td>\n",
       "      <td>ZW - Tornado Bringer</td>\n",
       "      <td>-1</td>\n",
       "      <td>You can target 1 \"Utopia\" monster you control;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Aqua</td>\n",
       "      <td>-1</td>\n",
       "      <td>Effect Monster</td>\n",
       "      <td>-1</td>\n",
       "      <td>EARTH</td>\n",
       "      <td>-1</td>\n",
       "      <td>ZW - Ultimate Shield</td>\n",
       "      <td>-1</td>\n",
       "      <td>When this card is Normal or Special Summoned: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12460</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Beast</td>\n",
       "      <td>-1</td>\n",
       "      <td>Effect Monster</td>\n",
       "      <td>-1</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>-1</td>\n",
       "      <td>ZW - Unicorn Spear</td>\n",
       "      <td>-1</td>\n",
       "      <td>You can target 1 \"Number C39: Utopia Ray\" you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12461 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level  A1        race  A3            type  A5 attribute  A7  \\\n",
       "0          0  -1  Continuous  -1      Spell Card  -1         0  -1   \n",
       "1          0  -1  Continuous  -1      Spell Card  -1         0  -1   \n",
       "2          0  -1  Quick-Play  -1      Spell Card  -1         0  -1   \n",
       "3          0  -1  Quick-Play  -1      Spell Card  -1         0  -1   \n",
       "4          0  -1       Equip  -1      Spell Card  -1         0  -1   \n",
       "...      ...  ..         ...  ..             ...  ..       ...  ..   \n",
       "12456      4  -1       Beast  -1  Effect Monster  -1     LIGHT  -1   \n",
       "12457      4  -1       Beast  -1  Effect Monster  -1     LIGHT  -1   \n",
       "12458      5  -1      Dragon  -1  Effect Monster  -1      WIND  -1   \n",
       "12459      4  -1        Aqua  -1  Effect Monster  -1     EARTH  -1   \n",
       "12460      4  -1       Beast  -1  Effect Monster  -1     LIGHT  -1   \n",
       "\n",
       "                                name  A9  \\\n",
       "0           \"A\" Cell Breeding Device  -1   \n",
       "1                 \"A\" Cell Incubator  -1   \n",
       "2      \"A\" Cell Recombination Device  -1   \n",
       "3             \"A\" Cell Scatter Burst  -1   \n",
       "4         \"Infernoble Arms - Almace\"  -1   \n",
       "...                              ...  ..   \n",
       "12456             ZW - Sleipnir Mail  -1   \n",
       "12457              ZW - Sylphid Wing  -1   \n",
       "12458           ZW - Tornado Bringer  -1   \n",
       "12459           ZW - Ultimate Shield  -1   \n",
       "12460             ZW - Unicorn Spear  -1   \n",
       "\n",
       "                                                    desc  \n",
       "0      During each of your Standby Phases, put 1 A-Co...  \n",
       "1      Each time an A-Counter(s) is removed from play...  \n",
       "2      Target 1 face-up monster on the field; send 1 ...  \n",
       "3      Select 1 face-up \"Alien\" monster you control. ...  \n",
       "4      While this card is equipped to a monster: You ...  \n",
       "...                                                  ...  \n",
       "12456  You can target 1 \"Utopia\" monster you control;...  \n",
       "12457  You can only control 1 \"ZW - Sylphid Wing\". Yo...  \n",
       "12458  You can target 1 \"Utopia\" monster you control;...  \n",
       "12459  When this card is Normal or Special Summoned: ...  \n",
       "12460  You can target 1 \"Number C39: Utopia Ray\" you ...  \n",
       "\n",
       "[12461 rows x 11 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sliced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf6d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Knightmare Phoenix', 'Called by the Grave', 'Infinite Impermanence', 'Infinite Impermanence', 'Infinite Impermanence']\n",
      "['Infinite Impermanence', 'Ash Blossom & Joyous Spring', 'Knightmare Phoenix', 'Knightmare Cerberus', 'Pot of Prosperity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7, -1, 246, 0, -1, 170, 8, 0, 0, -1, 279, -1,...</td>\n",
       "      <td>[0.0, -1.0, 766.0, 0.0, -1.0, 120.0, 8.0, 0.0,...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[97, -1, 866, 0, -1, 21, 8, 0, 0, -1, 297, -1,...</td>\n",
       "      <td>[276.0, -1.0, 286.0, 146.0, -1.0, 21.0, 8.0, 0...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, -1, 711, 0, -1, 80, 5, 0, 0, -1, 0, -1, 45...</td>\n",
       "      <td>[0.0, -1.0, 374.0, 0.0, -1.0, 120.0, 8.0, 0.0,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[194, -1, 374, 0, -1, 75, 8, 0, 0, -1, 198, -1...</td>\n",
       "      <td>[0.0, -1.0, 411.0, 0.0, -1.0, 120.0, 8.0, 0.0,...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, -1, 41, 0, -1, 80, 5, 0, 0, -1, 0, -1, 636...</td>\n",
       "      <td>[663.0, -1.0, 766.0, 0.0, -1.0, 21.0, 8.0, 0.0...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>[0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 172...</td>\n",
       "      <td>[276.0, -1.0, 286.0, 146.0, -1.0, 21.0, 8.0, 0...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>[7, -1, 286, 146, -1, 21, 8, 0, 0, -1, 297, -1...</td>\n",
       "      <td>[194.0, -1.0, 363.0, 0.0, -1.0, 85.0, 8.0, 0.0...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>[0, -1, 711, 0, -1, 80, 5, 0, 0, -1, 0, -1, 31...</td>\n",
       "      <td>[0.0, -1.0, 327.0, 0.0, -1.0, 80.0, 5.0, 0.0, ...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>[0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 808...</td>\n",
       "      <td>[0.0, -1.0, 59.0, 0.0, -1.0, 80.0, 5.0, 0.0, 0...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>[0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 105...</td>\n",
       "      <td>[194.0, -1.0, 274.0, 0.0, -1.0, 21.0, 8.0, 0.0...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     [7, -1, 246, 0, -1, 170, 8, 0, 0, -1, 279, -1,...   \n",
       "1     [97, -1, 866, 0, -1, 21, 8, 0, 0, -1, 297, -1,...   \n",
       "2     [0, -1, 711, 0, -1, 80, 5, 0, 0, -1, 0, -1, 45...   \n",
       "3     [194, -1, 374, 0, -1, 75, 8, 0, 0, -1, 198, -1...   \n",
       "4     [0, -1, 41, 0, -1, 80, 5, 0, 0, -1, 0, -1, 636...   \n",
       "...                                                 ...   \n",
       "1583  [0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 172...   \n",
       "1584  [7, -1, 286, 146, -1, 21, 8, 0, 0, -1, 297, -1...   \n",
       "1585  [0, -1, 711, 0, -1, 80, 5, 0, 0, -1, 0, -1, 31...   \n",
       "1586  [0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 808...   \n",
       "1587  [0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 105...   \n",
       "\n",
       "                                                      1    2  \n",
       "0     [0.0, -1.0, 766.0, 0.0, -1.0, 120.0, 8.0, 0.0,...  [0]  \n",
       "1     [276.0, -1.0, 286.0, 146.0, -1.0, 21.0, 8.0, 0...  [0]  \n",
       "2     [0.0, -1.0, 374.0, 0.0, -1.0, 120.0, 8.0, 0.0,...  [1]  \n",
       "3     [0.0, -1.0, 411.0, 0.0, -1.0, 120.0, 8.0, 0.0,...  [0]  \n",
       "4     [663.0, -1.0, 766.0, 0.0, -1.0, 21.0, 8.0, 0.0...  [0]  \n",
       "...                                                 ...  ...  \n",
       "1583  [276.0, -1.0, 286.0, 146.0, -1.0, 21.0, 8.0, 0...  [1]  \n",
       "1584  [194.0, -1.0, 363.0, 0.0, -1.0, 85.0, 8.0, 0.0...  [1]  \n",
       "1585  [0.0, -1.0, 327.0, 0.0, -1.0, 80.0, 5.0, 0.0, ...  [1]  \n",
       "1586  [0.0, -1.0, 59.0, 0.0, -1.0, 80.0, 5.0, 0.0, 0...  [0]  \n",
       "1587  [194.0, -1.0, 274.0, 0.0, -1.0, 21.0, 8.0, 0.0...  [1]  \n",
       "\n",
       "[1588 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Deck_Loader(directory):\n",
    "    '''Loads Decks from Deck_Lists.txt as arrays and stores those arrays in altered'''\n",
    "    file = open(directory , 'r')\n",
    "    read = file.readlines()\n",
    "    Deck_Array = []\n",
    "    flag = False\n",
    "\n",
    "    temp=[]\n",
    "\n",
    "    for count,line in enumerate(read):\n",
    "        \n",
    "        if '//' in read[count]:\n",
    "            flag = not flag\n",
    "        \n",
    "        if flag:\n",
    "            \n",
    "            read[count] = read[count].replace('\\n','')\n",
    "            \n",
    "            if ('=='  in read[count]) or ('//'  in read[count])  :\n",
    "                pass\n",
    "                \n",
    "            else:\n",
    "                for i in range(int(read[count][0])):\n",
    "                    temp.append(read[count][1:].strip())          #skip appending also remove white space\n",
    "\n",
    "        if (not flag) or (count == len(read) - 1):\n",
    "            Deck_Array.append(temp)\n",
    "            temp = []\n",
    "            flag = not flag\n",
    "            \n",
    "            \n",
    "    file.close()\n",
    "    return Deck_Array \n",
    "\n",
    "\n",
    "def stitcher(Deck_Index , Deck_Array , Random_Flag , Input_Array):\n",
    "    '''Picks 5 random cards from a certain deck in a deck array and stitches them together. Or just stitches cards from input array together.'''\n",
    "    if Random_Flag:\n",
    "        decider = [random.choice(Deck_Array[Deck_Index]) for _ in range(5)]\n",
    "    else:\n",
    "        decider = Input_Array\n",
    "\n",
    "    ###If decider picks all staples then error can occur with an empty array hence recalls stitcher function.    \n",
    "    try:\n",
    "        output = np.concatenate(([Tokenized_sequence_database[i] for i in Sliced_df[Sliced_df['name'].isin(decider)].index.values]) )\n",
    "    except:\n",
    "        print(decider)\n",
    "        return stitcher(Deck_Index , Deck_Array , Random_Flag , Input_Array)\n",
    "\n",
    "    if len(output) != 905:\n",
    "        return stitcher(Deck_Index , Deck_Array , Random_Flag , Input_Array)\n",
    "    else:\n",
    "        return output\n",
    "\n",
    "def no_match_generator(length , Deck_Array):\n",
    "    '''Generated Datapoints which correspond to a card that doesnt relate to a given group of decider cards'''\n",
    "    out = []\n",
    "    for _ in range(length):\n",
    "        ran_deck = random.choice(Deck_Array)\n",
    "        ran_indx = random.choice(Sliced_df[Sliced_df['name'].isin(ran_deck)].index.values)\n",
    "\n",
    "        temp = []\n",
    "        #Incase card chosen is a staple, it skips it.\n",
    "        try:\n",
    "            subject_card = np.concatenate( ( Tokenized_sequence_database[ran_indx]  , np.zeros(724)) , axis=None )\n",
    "            decider_cards = np.concatenate([random.choice(Tokenized_sequence_database) for _ in range(5)])\n",
    "\n",
    "            temp.append(decider_cards)\n",
    "            temp.append(subject_card)\n",
    "            temp.append([0])\n",
    "\n",
    "            out.append(temp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return out\n",
    "\n",
    "def Dataset_Builder(directory , include_no_match):\n",
    "    '''Builds a dataset with some specificaiton. This could be a training/validation dataset or a experimentation dataset'''\n",
    "    altered = Deck_Loader(directory)\n",
    "    Built_Dataset = []\n",
    "    for deck_index,deck in enumerate(altered):\n",
    "        \n",
    "        for card_index in Sliced_df[Sliced_df['name'].isin(deck)].index.values:\n",
    "            \n",
    "            subject_card =  np.concatenate( (Tokenized_sequence_database[card_index] , np.zeros(724)) , axis=None ) # Extends subject to equal length of decider cards\n",
    "            for _ in range(2):\n",
    "                temp = []\n",
    "                decider_cards = stitcher(deck_index , altered , True, [])\n",
    "                temp.append(decider_cards)\n",
    "                temp.append(subject_card)\n",
    "                temp.append([1])\n",
    "                Built_Dataset.append(temp)\n",
    "\n",
    "\n",
    "    if (include_no_match):\n",
    "        Built_Dataset.extend( no_match_generator(len(Built_Dataset) , altered) )\n",
    "    random.shuffle(Built_Dataset)\n",
    "    random.shuffle(Built_Dataset)\n",
    "    random.shuffle(Built_Dataset)\n",
    "    return Built_Dataset\n",
    "\n",
    "\n",
    "\n",
    "Training_Validation_Dataset = Dataset_Builder('Dataset/Deck_Lists.txt' , True)\n",
    "pd.DataFrame(Training_Validation_Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d58ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nibiru, the Primal Being', 'D.D. Crow', 'Dark Ruler No More', 'D.D. Crow', 'D.D. Crow']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[276, -1, 363, 0, -1, 85, 8, 0, 0, -1, 138, -1...</td>\n",
       "      <td>[465.0, -1.0, 414.0, 0.0, -1.0, 21.0, 8.0, 0.0...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, -1, 59, 0, -1, 111, 5, 0, 0, -1, 0, -1, 28...</td>\n",
       "      <td>[61.0, -1.0, 387.0, 0.0, -1.0, 21.0, 8.0, 0.0,...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 547...</td>\n",
       "      <td>[0.0, -1.0, 59.0, 0.0, -1.0, 80.0, 5.0, 0.0, 0...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, -1, 59, 0, -1, 111, 5, 0, 0, -1, 0, -1, 0,...</td>\n",
       "      <td>[0.0, -1.0, 387.0, 0.0, -1.0, 120.0, 8.0, 0.0,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[465, -1, 371, 0, -1, 93, 8, 0, 0, -1, 138, -1...</td>\n",
       "      <td>[97.0, -1.0, 371.0, 0.0, -1.0, 21.0, 8.0, 0.0,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[114, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1...</td>\n",
       "      <td>[334.0, -1.0, 371.0, 0.0, -1.0, 93.0, 8.0, 0.0...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>[114, -1, 374, 0, -1, 93, 8, 0, 0, -1, 198, -1...</td>\n",
       "      <td>[61.0, -1.0, 411.0, 0.0, -1.0, 75.0, 8.0, 0.0,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>[114, -1, 301, 0, -1, 21, 8, 0, 0, -1, 138, -1...</td>\n",
       "      <td>[0.0, -1.0, 327.0, 0.0, -1.0, 111.0, 5.0, 0.0,...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>[114, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1...</td>\n",
       "      <td>[0.0, -1.0, 59.0, 0.0, -1.0, 111.0, 5.0, 0.0, ...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[97, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1,...</td>\n",
       "      <td>[61.0, -1.0, 387.0, 0.0, -1.0, 21.0, 8.0, 0.0,...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0    [276, -1, 363, 0, -1, 85, 8, 0, 0, -1, 138, -1...   \n",
       "1    [0, -1, 59, 0, -1, 111, 5, 0, 0, -1, 0, -1, 28...   \n",
       "2    [0, -1, 59, 0, -1, 80, 5, 0, 0, -1, 0, -1, 547...   \n",
       "3    [0, -1, 59, 0, -1, 111, 5, 0, 0, -1, 0, -1, 0,...   \n",
       "4    [465, -1, 371, 0, -1, 93, 8, 0, 0, -1, 138, -1...   \n",
       "..                                                 ...   \n",
       "499  [114, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1...   \n",
       "500  [114, -1, 374, 0, -1, 93, 8, 0, 0, -1, 198, -1...   \n",
       "501  [114, -1, 301, 0, -1, 21, 8, 0, 0, -1, 138, -1...   \n",
       "502  [114, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1...   \n",
       "503  [97, -1, 371, 0, -1, 21, 8, 0, 0, -1, 138, -1,...   \n",
       "\n",
       "                                                     1    2  \n",
       "0    [465.0, -1.0, 414.0, 0.0, -1.0, 21.0, 8.0, 0.0...  [0]  \n",
       "1    [61.0, -1.0, 387.0, 0.0, -1.0, 21.0, 8.0, 0.0,...  [0]  \n",
       "2    [0.0, -1.0, 59.0, 0.0, -1.0, 80.0, 5.0, 0.0, 0...  [1]  \n",
       "3    [0.0, -1.0, 387.0, 0.0, -1.0, 120.0, 8.0, 0.0,...  [1]  \n",
       "4    [97.0, -1.0, 371.0, 0.0, -1.0, 21.0, 8.0, 0.0,...  [1]  \n",
       "..                                                 ...  ...  \n",
       "499  [334.0, -1.0, 371.0, 0.0, -1.0, 93.0, 8.0, 0.0...  [1]  \n",
       "500  [61.0, -1.0, 411.0, 0.0, -1.0, 75.0, 8.0, 0.0,...  [1]  \n",
       "501  [0.0, -1.0, 327.0, 0.0, -1.0, 111.0, 5.0, 0.0,...  [1]  \n",
       "502  [0.0, -1.0, 59.0, 0.0, -1.0, 111.0, 5.0, 0.0, ...  [1]  \n",
       "503  [61.0, -1.0, 387.0, 0.0, -1.0, 21.0, 8.0, 0.0,...  [0]  \n",
       "\n",
       "[504 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a experimentation decklist with same format and push it to builder to build out a dataset. Put sequences into the sequence to text converters to see relation table with names.\n",
    "# See how accurate model is at predicting card relations withing a deck -> It should predict most cards as 1.\n",
    "\n",
    "# Create a function which allows you to type 5 cards and the create a dataset with every other card in the game as a subject and see what cards the model predicts will go well with your chosen cards.\n",
    "\n",
    "Experimentation_Dataset = Dataset_Builder('Dataset/Experimental_Deck_Lists.txt' , True)\n",
    "pd.DataFrame(Experimentation_Dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ac5140d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  -1, 327, ...,   0,   0,   0],\n",
       "       [  0,  -1, 327, ...,   0,   0,   0],\n",
       "       [  0,  -1, 711, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [194,  -1,  99, ...,   0,   0,   0],\n",
       "       [114,  -1, 866, ...,   0,   0,   0],\n",
       "       [114,  -1, 146, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenized_sequence_database\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbd1ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate( [np.sin(angle_rads), np.cos(angle_rads)], axis=-1) \n",
    "\n",
    "  return pos_encoding\n",
    "\n",
    "class Positional_Embedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=False) \n",
    "    self.pos_encoding = positional_encoding(length=905, depth=d_model)\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.embedding(x)\n",
    "    \n",
    "    #x*= np.sqrt(self.d_model) # Scale Values by their embedding dimensionality otherwise they could get overwhelmed by positional encoder\n",
    "    #x = x + self.pos_encoding \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "class DeciderSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    \n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, ffn, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(ffn, activation='relu'), \n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x\n",
    "  \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  \"\"\"Single Encoder Layer with DeciderMHA and Feed Forward layer\"\"\"\n",
    "  def __init__(self, d_model, ffn , dropout_rate ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.DSA = DeciderSelfAttention(num_heads=4, key_dim=100)       # Scaling Number of Heads increases parameters as this is a different implementation of mha compared to attention is all you need paper.\n",
    "    self.FF = FeedForward(d_model, ffn , dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    \n",
    "    \n",
    "    x = self.DSA(x)\n",
    "\n",
    "    x = self.FF(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  \"\"\"Full Encoder with embedding layer with dropout and encoder layers\"\"\"\n",
    "  def __init__(self, d_model, vocab_size , ffn , dropout_rate , num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.Pos_Embedding = Positional_Embedding(vocab_size, d_model)\n",
    "    self.EL = [EncoderLayer(d_model, ffn , dropout_rate) for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self,x):\n",
    "    \n",
    "    x = self.Pos_Embedding(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.EL[i](x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class SubjectSelfAttention(BaseAttention):\n",
    "  \n",
    "  def call(self, x):\n",
    "    \n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    \n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class SubjectCrossAttention(BaseAttention):\n",
    "\n",
    "  def call(self, x , context):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        key=context)\n",
    "    \n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class ComparatorLayer(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self , d_model, ffn , dropout_rate):\n",
    "    super().__init__()\n",
    "\n",
    "    self.SSA = SubjectSelfAttention(num_heads=4, key_dim=100)      \n",
    "    self.SCA = SubjectCrossAttention(num_heads=4, key_dim=100)\n",
    "    self.FF = FeedForward(d_model, ffn , dropout_rate)\n",
    "\n",
    "  def call(self, x , context):\n",
    "    \n",
    "    x = self.SSA(x)\n",
    "\n",
    "    x = self.SCA(x , context)\n",
    "\n",
    "    x = self.FF(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "class Comparator(tf.keras.layers.Layer):\n",
    "  \n",
    "  def __init__(self, d_model, vocab_size , ffn , dropout_rate , num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.Pos_Embedding = Positional_Embedding(vocab_size, d_model)\n",
    "    self.CL = [ComparatorLayer(d_model, ffn , dropout_rate) for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x , context):\n",
    "    \n",
    "    x = self.Pos_Embedding(x)\n",
    "    \n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.CL[i](x , context)\n",
    "\n",
    "    return x\n",
    "\n",
    "class FinalFeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self , dropout_rate):\n",
    "    super().__init__()\n",
    "\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(),          #Flattens sentances for each card comparision , into a single 1d array , so it can generate probabilities properly, instead of shoving 100 x905 matrix straight through and generating 100 probabilities for each card comparision feature embedding\n",
    "      tf.keras.layers.Dense(50, activation='relu'),\n",
    "      tf.keras.layers.Dense(25, activation='relu'),\n",
    "      tf.keras.layers.Dropout(dropout_rate),\n",
    "      tf.keras.layers.Dense(1 , activation='sigmoid')\n",
    "      \n",
    "    ])\n",
    "    \n",
    "  def call(self, x):\n",
    "    \n",
    "    x = self.seq(x) \n",
    "    return x\n",
    "  \n",
    "class FullModel(tf.keras.Model):\n",
    "   def __init__(self, d_model, vocab_size , ffn , dropout_rate , num_layers):\n",
    "    super().__init__()\n",
    "\n",
    "    self.enc = Encoder(d_model, vocab_size , ffn , dropout_rate , num_layers)\n",
    "    self.com = Comparator(d_model, vocab_size , ffn , dropout_rate , num_layers)\n",
    "    self.FFF = FinalFeedForward(dropout_rate)\n",
    "\n",
    "   def call(self, inputs):\n",
    "     context , x = inputs\n",
    "     \n",
    "     \n",
    "     \n",
    "     context = self.enc(context)\n",
    "    \n",
    "     x = self.com(x , context)\n",
    "\n",
    "     x = self.FFF(x)\n",
    "\n",
    "     return x\n",
    "   \n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0d46854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 905), dtype=int32, numpy=\n",
       "array([[ 97,  -1, 146,   0,  -1,  59,   8,   0,   0,  -1, 279,  -1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  -1, 150,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7035acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#subject_card = Positional_Embedding(12647 , 100 )(subject_card)\n",
    "\n",
    "emb = Positional_Embedding(12647 , 100)\n",
    "comp_test = Comparator(100 , 12647 , 1000 , 0.3 , 2)\n",
    "compL_test = ComparatorLayer(100 , 1000 , 0.3)\n",
    "FM_Test = FullModel(100 , 12647 , 1000 , 0.3 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cfba82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 905, 100), dtype=float32, numpy=\n",
       "array([[[-0.04667787, -0.00644787,  0.00574112, ...,  0.01819483,\n",
       "          0.02517973, -0.01179622],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.00734416,  0.04132183, -0.01791579, ..., -0.03784325,\n",
       "          0.03174325, -0.04850903],\n",
       "        ...,\n",
       "        [-0.04667787, -0.00644787,  0.00574112, ...,  0.01819483,\n",
       "          0.02517973, -0.01179622],\n",
       "        [-0.04667787, -0.00644787,  0.00574112, ...,  0.01819483,\n",
       "          0.02517973, -0.01179622],\n",
       "        [-0.04667787, -0.00644787,  0.00574112, ...,  0.01819483,\n",
       "          0.02517973, -0.01179622]]], dtype=float32)>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(subject_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b86e1a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc ran\n",
      "In comparator, before passing through pos embedding x , has a shape of:\n",
      "tf.Tensor([  1 905], shape=(2,), dtype=int32)\n",
      "In comparator, after passing through pos embedding x , has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n",
      "In comparator, after passing through dropout x , has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n",
      "In ComparatorLayer, before SSa , x has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n",
      "In SSa , x has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n",
      "In ComparatorLayer, before SSa , x has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n",
      "In SSa , x has a shape of:\n",
      "tf.Tensor([  1 905 100], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.42610976]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "input_array = ['Galaxy Wizard' , 'Galaxy Soldier' , 'Photon Orbital' , 'Galaxy-Eyes Photon Dragon' ,'Galaxy Summoner']\n",
    "\n",
    "decider1 = tf.convert_to_tensor([stitcher(0 , [] , False, input_array)])\n",
    "subject_card1 = tf.convert_to_tensor(    [np.concatenate( (Tokenized_sequence_database[7] , np.zeros(724)) , axis=None )]     ) \n",
    "\n",
    "\n",
    "# decider2 = tf.convert_to_tensor([stitcher(0 , [] , False, input_array)])\n",
    "# subject_card2 = tf.convert_to_tensor(    [np.concatenate( (Tokenized_sequence_database[8434] , np.zeros(724)) , axis=None )]     ) \n",
    "# sm = 0\n",
    "# for i in (compL_test(emb(subject_card1) , emb(decider1)) - compL_test(emb(subject_card2) , emb(decider2)))[0][0]:\n",
    "#     sm+=i\n",
    "#compL_test(emb(subject_card1) , emb(decider1))\n",
    "# print(sm) \n",
    "#print(Model.predict((decider , subject_card))[0])\n",
    "#sum(abs((compL_test(emb(subject_card1) , emb(decider1)) - compL_test(emb(subject_card2) , emb(decider2)))[0][0]))\n",
    "FM_Test((decider1 , subject_card1))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e68f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Train_Gen():\n",
    "    seti0 = [i[0] for i in Training_Validation_Dataset]\n",
    "    seti1 = [i[1] for i in Training_Validation_Dataset]\n",
    "    seti2 = [i[2] for i in Training_Validation_Dataset]\n",
    "    for _ in range(2000):\n",
    "        r_int = random.randint(0 , len(Training_Validation_Dataset) - 20)\n",
    "        train_seti0 = tf.convert_to_tensor(seti0[r_int:r_int+20])\n",
    "        train_seti1 = tf.convert_to_tensor(seti1[r_int:r_int+20])\n",
    "        train_seti2 = tf.convert_to_tensor(seti2[r_int:r_int+20])\n",
    "    \n",
    "        yield (train_seti0,train_seti1), train_seti2\n",
    "\n",
    "def Val_Gen():\n",
    "    seti0 = [i[0] for i in Experimentation_Dataset]\n",
    "    seti1 = [i[1] for i in Experimentation_Dataset]\n",
    "    seti2 = [i[2] for i in Experimentation_Dataset]\n",
    "    for _ in range(1000):\n",
    "        r_int = random.randint(0 , len(Experimentation_Dataset) - 20)\n",
    "        val_seti0 = tf.convert_to_tensor(seti0[r_int:r_int+20])\n",
    "        val_seti1 = tf.convert_to_tensor(seti1[r_int:r_int+20])\n",
    "        val_seti2 = tf.convert_to_tensor(seti2[r_int:r_int+20])\n",
    "\n",
    "        yield (val_seti0,val_seti1), val_seti2\n",
    "\n",
    "def Experimentation_Gen():\n",
    "    seti0 = [i[0] for i in Experimentation_Dataset]\n",
    "    seti1 = [i[1] for i in Experimentation_Dataset]\n",
    "    seti2 = [i[2] for i in Experimentation_Dataset]\n",
    "\n",
    "    for _ in range(len(Experimentation_Dataset)):\n",
    "        # For some reason i doesnt iterate and gets stuck at 0 , so had to use random int\n",
    "        r_int = random.randint(0 , 90)\n",
    "        exp_seti0 = tf.convert_to_tensor(seti0[r_int:r_int+1])\n",
    "        exp_seti1 = tf.convert_to_tensor(seti1[r_int:r_int+1])\n",
    "        exp_seti2 = tf.convert_to_tensor(seti2[r_int:r_int+1])\n",
    "\n",
    "        yield (exp_seti0,exp_seti1), exp_seti2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2603da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7278 - accuracy: 0.5050 - val_loss: 0.7207 - val_accuracy: 0.5260\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.5500"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax' defined at (most recent call last):\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\2342074098.py\", line 13, in <module>\n      history = Model.fit(Train_Gen() , epochs=20,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1606, in fit\n      val_logs = self.evaluate(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n      y_pred = self(x, training=False)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 207, in call\n      x = self.com(x , context)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 169, in call\n      for i in range(self.num_layers):\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 170, in call\n      x = self.CL[i](x , context)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 144, in call\n      x = self.SSA(x)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 112, in call\n      attn_output = self.mha(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 596, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 527, in _compute_attention\n      attention_scores = self._masked_softmax(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 493, in _masked_softmax\n      return self._softmax(attention_scores, attention_mask)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\activation\\softmax.py\", line 103, in call\n      return backend.softmax(inputs, axis=self.axis[0])\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5413, in softmax\n      return tf.nn.softmax(x, axis=axis)\nNode: 'full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax'\nOOM when allocating tensor with shape[50,4,905,905] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_33478]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.98\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n\u001b[0;32m      8\u001b[0m Model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     11\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrain_Gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVal_Gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax' defined at (most recent call last):\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\2342074098.py\", line 13, in <module>\n      history = Model.fit(Train_Gen() , epochs=20,\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1606, in fit\n      val_logs = self.evaluate(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n      y_pred = self(x, training=False)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 207, in call\n      x = self.com(x , context)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 169, in call\n      for i in range(self.num_layers):\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 170, in call\n      x = self.CL[i](x , context)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 144, in call\n      x = self.SSA(x)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\X99S5\\AppData\\Local\\Temp\\ipykernel_14340\\3292563555.py\", line 112, in call\n      attn_output = self.mha(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 596, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 527, in _compute_attention\n      attention_scores = self._masked_softmax(\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 493, in _masked_softmax\n      return self._softmax(attention_scores, attention_mask)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\activation\\softmax.py\", line 103, in call\n      return backend.softmax(inputs, axis=self.axis[0])\n    File \"c:\\Users\\X99S5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5413, in softmax\n      return tf.nn.softmax(x, axis=axis)\nNode: 'full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax'\nOOM when allocating tensor with shape[50,4,905,905] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node full_model_4/comparator_6/comparator_layer_14/subject_self_attention_14/multi_head_attention_38/softmax_26/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_33478]"
     ]
    }
   ],
   "source": [
    "#Testing accuracy is much higher than training accuracy. This is due to dropouts causing lower accuracy during training but giving a more robust model when testing\n",
    "Model = FullModel(100 , 12647 , 1000 , 0.2 , 2)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model = 100)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "Model.compile(\n",
    "    loss= tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=optimizer,\n",
    "    metrics= 'accuracy' )\n",
    "\n",
    "history = Model.fit(Train_Gen() , epochs=20, \n",
    "                               validation_data = Val_Gen()  , steps_per_epoch=10 , batch_size=20 , validation_steps=10 , validation_batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c6848a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Enc ran\n",
      "Com ran\n",
      "1/1 [==============================] - 1s 837ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.6818564]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.6818564]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [384], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;66;03m# if Model.predict((decider , subject_card) , verbose=False)[0][0] > 0.1:\u001b[39;00m\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;66;03m#     print(Sliced_df[indx:indx+1]['name'])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mpredict_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [384], line 17\u001b[0m, in \u001b[0;36mpredict_matches\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#subject_card = tf.convert_to_tensor([np.zeros(905) ])\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#print(subject_card)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Model\u001b[38;5;241m.\u001b[39mpredict((decider , subject_card))[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# if Model.predict((decider , subject_card) , verbose=False)[0][0] > 0.1:\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#     print(Sliced_df[indx:indx+1]['name'])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[0;32m     22\u001b[0m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def predict_matches():\n",
    "    #input_array = [input('enter') for _ in range(5)]\n",
    "    input_array = ['Galaxy Wizard' , 'Galaxy Soldier' , 'Photon Orbital' , 'Galaxy-Eyes Photon Dragon' ,'Galaxy Summoner']\n",
    "    \n",
    "    decider = tf.convert_to_tensor([stitcher(0 , [] , False, input_array)])\n",
    "    count = 0\n",
    "    for indx in pd.DataFrame(Tokenized_sequence_database).index.values:\n",
    "        if count<2500:\n",
    "            pass\n",
    "        else:\n",
    "            if (count % 100) == 0:\n",
    "                print(count)\n",
    "            subject_card = tf.convert_to_tensor([np.concatenate( (Tokenized_sequence_database[indx] , np.zeros(724)) , axis=None )])\n",
    "            #subject_card = tf.convert_to_tensor([np.zeros(905) ])\n",
    "            #print(subject_card)\n",
    "            print(Model.predict((decider , subject_card))[0])\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # if Model.predict((decider , subject_card) , verbose=False)[0][0] > 0.1:\n",
    "            #     print(Sliced_df[indx:indx+1]['name'])\n",
    "            #     break\n",
    "        count+=1\n",
    "predict_matches()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1cb6a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 8s 12ms/step\n",
      "0.16468253968253968\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame(Model.predict(Experimentation_Gen()))\n",
    "count = 0\n",
    "for i in pred[0]:\n",
    "    if i > 0.5:\n",
    "        count+=1\n",
    "print(count/len(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 219ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9966325]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k , trash = next(Experimentation_Gen())\n",
    "l1 , l2 = k\n",
    "singular_pred = Model.predict(k)\n",
    "singular_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9e8875d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2 aqua effect monster water cannot be used as a synchro material. this card's name becomes des frog while it is on the field. if this card is in your graveyard: you can banish 1 frog monster from your graveyard; special summon this card.\"]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.sequences_to_texts([l2[0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d9ca161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200 % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638286c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67126460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a360e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff4a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fffee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5b519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf9a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd683030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
